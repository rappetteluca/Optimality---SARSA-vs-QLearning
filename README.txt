AI 5

By Lucas Rappette

This Project's "main" class is ReinforcementLearning.java; It doesn't take any arguments.

To start learning on a new iceWorld simply replace "iceWorld.txt" with any valid grid specification.


The 4 Text Files included are automatically generated by the program. The "Rewards" text files are the rewardsGained for each episode for a specific algorithm.
This was to allow ease of copying and pasting in to Excel. They are many additional formatting Strings (for your readAbility) commented out inside the sourceCode.

Overall the Q-Learning Algorithm works way better then the SARSA algorithm, which is counterintuitive. Additional Guidance on why SARSA settles for
localMins and painful converging would be needed to make this a good program.  



PDF Note: Since I have no idea how to create PDF files on the fly I have included a premade pdf of a sample run I performed Earlier today.
You can create your own graphs following my exact same layout by copying and pasting the rewards distribution from the output files into the appropriate columns in the Xcel document I have included.


**Instructor Note**: The "weird" results you noted for SARSA are actually exactly what we expect.  Due to its "on-policy" approach it tends to play it safe.  With a much longer time horizon and slower randomness reduction, we could probably get rid of this, but over the time given, the difference between the two algorithms is to be expected.